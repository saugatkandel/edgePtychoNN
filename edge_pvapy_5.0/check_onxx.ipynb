{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8759c897-a4ac-4245-8ea0-6e6c3296353f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tensorrt as trt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cbb202-3a99-45fb-bb45-9b6e394edb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from onnx import helper, shape_inference\n",
    "from onnx import TensorProto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44742e3c-59c2-47df-9a7f-a69bcb2d7314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f380cf86-1423-4975-81ea-eea37e211e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATHS = {\n",
    "    \"128\": \"/home/beams/ABABU/ptychoNN-test/new_models/training4_1.8khz/ptychoNN_8.onnx\",\n",
    "    \"512\": \"/home/beams/SKANDEL/code/anakha_ptychoNN-test/models_02_10_23/ptychoNN_8.onnx\",\n",
    "}\n",
    "\n",
    "CURRENT_MODEL = \"512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648f5f0e-a43f-45de-821c-097bcd1339f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basic_check(model, print_graph: bool = False):\n",
    "\n",
    "    # Check that the model is well formed\n",
    "    onnx.checker.check_model(model)\n",
    "\n",
    "    if print_graph:\n",
    "        # Print a human readable representation of the graph\n",
    "        print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84f53f1-1d39-4fc9-9aaf-ea99e9e814c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shape_check(model, print_graph: bool = False):\n",
    "    inferred_model = shape_inference.infer_shapes(model)\n",
    "    onnx.checker.check_model(inferred_model)\n",
    "    if print_graph:\n",
    "        # Print a human readable representation of the graph\n",
    "        print(onnx.helper.printable_graph(inferred_model.graph))\n",
    "        #print(f\"After shape inference, the shape info of Y is:\\n{inferred_model.graph.value_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44239e5-5349-4d2e-a03c-a3bc0d36875d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = onnx.load(MODEL_PATHS[CURRENT_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197baff3-1dc6-4164-b7ba-2951ba26c57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_check(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bf4757-44b4-422b-b649-03a6e9f6df98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = ort.InferenceSession(MODEL_PATHS[CURRENT_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83cc874-e737-4b9c-a603-45f468a7e223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name: input.1\n"
     ]
    }
   ],
   "source": [
    "# get the name of the first input of the model\n",
    "input_name = sess.get_inputs()[0].name  \n",
    "\n",
    "print('Input Name:', input_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d66c36f7-c125-4135-a623-738f7d99745c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = np.random.random((8, 1, 512, 512)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76232f6e-6287-4965-8fd3-d35ebb410bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outp = sess.run(None, {'input.1':inp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df183a5-617e-4f21-994d-7d449b556be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 1, 128, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31132704-37c9-4578-8be1-d6fc41a7387a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NetworkDefinitionCreationFlag.EXPLICIT_BATCH: 0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a900864-f1f7-47e2-87cc-27ba56395a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073741824"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * (1 << 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a5c7588-4189-4cec-bba6-b7530eee4ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engine_build_from_onnx(onnx_mdl):\n",
    "    EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    config = builder.create_builder_config()\n",
    "    # config.set_flag(trt.BuilderFlag.FP16)\n",
    "    config.set_flag(trt.BuilderFlag.TF32)\n",
    "    config.max_workspace_size = 1 * (1 << 50)  # the maximum size that any layer in the network can use\n",
    "\n",
    "    network = builder.create_network(EXPLICIT_BATCH)\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
    "    success = parser.parse_from_file(onnx_mdl)\n",
    "\n",
    "    for idx in range(parser.num_errors):\n",
    "        print(parser.get_error(idx))\n",
    "\n",
    "    if not success:\n",
    "        return None\n",
    "\n",
    "    return builder.build_engine(network, config)\n",
    "\n",
    "\n",
    "def mem_allocation(engine):\n",
    "    # Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\n",
    "\n",
    "    in_sz = trt.volume(engine.get_binding_shape(0)) * engine.max_batch_size\n",
    "    h_input = cuda.pagelocked_empty(in_sz, dtype=\"float32\")\n",
    "\n",
    "    out_sz = trt.volume(engine.get_binding_shape(1)) * engine.max_batch_size\n",
    "    h_output = cuda.pagelocked_empty(out_sz, dtype=\"float32\")\n",
    "\n",
    "    # Allocate device memory for inputs and outputs.\n",
    "    d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "\n",
    "    # Create a stream in which to copy inputs/outputs and run inference.\n",
    "    stream = cuda.Stream()\n",
    "\n",
    "    return h_input, h_output, d_input, d_output, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f6ca3b2-6d9f-46ab-9823-4d2ff74692e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2196033/4054450994.py:8: DeprecationWarning: Use set_memory_pool_limit instead.\n",
      "  config.max_workspace_size = 1 * (1 << 50)  # the maximum size that any layer in the network can use\n",
      "/tmp/ipykernel_2196033/4054450994.py:21: DeprecationWarning: Use build_serialized_network instead.\n",
      "  return builder.build_engine(network, config)\n"
     ]
    }
   ],
   "source": [
    "engine = engine_build_from_onnx(MODEL_PATHS[\"128\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be267e40-eacf-42d7-a70b-e2e236d08fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2196033/1690288493.py:1: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  engine.max_batch_size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.max_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe1e19b9-366c-4f32-b04a-581596e75d62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2196033/4054450994.py:27: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  in_sz = trt.volume(engine.get_binding_shape(0)) * engine.max_batch_size\n",
      "/tmp/ipykernel_2196033/4054450994.py:27: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
      "  in_sz = trt.volume(engine.get_binding_shape(0)) * engine.max_batch_size\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "explicit_context_dependent failed: invalid device context - no currently active context?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmem_allocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m, in \u001b[0;36mmem_allocation\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmem_allocation\u001b[39m(engine):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) to hold host inputs/outputs.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     in_sz \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mvolume(engine\u001b[38;5;241m.\u001b[39mget_binding_shape(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m engine\u001b[38;5;241m.\u001b[39mmax_batch_size\n\u001b[0;32m---> 28\u001b[0m     h_input \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagelocked_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_sz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     out_sz \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mvolume(engine\u001b[38;5;241m.\u001b[39mget_binding_shape(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m engine\u001b[38;5;241m.\u001b[39mmax_batch_size\n\u001b[1;32m     31\u001b[0m     h_output \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mpagelocked_empty(out_sz, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLogicError\u001b[0m: explicit_context_dependent failed: invalid device context - no currently active context?"
     ]
    }
   ],
   "source": [
    "mem_allocation(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b09c18-b2fc-47a8-ba1e-4f0de389b897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgeptychonn",
   "language": "python",
   "name": "edgeptychonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
